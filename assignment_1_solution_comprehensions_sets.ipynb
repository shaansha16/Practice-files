{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1fa078e",
   "metadata": {},
   "source": [
    "<h2 align=\"center\" style=\"color:blue\">Codebasics Python Course: Exercise - Comprehensions, Sets</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d101176-0b63-4bc8-b211-b08e066288da",
   "metadata": {},
   "source": [
    "**Loki** shared a few ad-hoc tasks that his team is working on across different projects at **AtliQ**, and now you will be helping him with them.\n",
    "\n",
    "<img src=\"https://files.codebasics.io/55188/avatar/lokhi.png\" width=\"10%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01689d55",
   "metadata": {},
   "source": [
    "### Task 1: Inventory Analysis for E-Commerce Client\n",
    "\n",
    "**AtliQ**, a service-based software company, is supporting an e-commerce client in analyzing their inventory data. The client wants to gain insights into the range of product categories available in their inventory. Your task, as part of the AtliQ team, is to identify and print all the unique product categories from a list of product records provided.\n",
    "\n",
    "You will be given a dataset containing product details, and your goal is to extract and display the distinct product categories present in the inventory.\n",
    "\n",
    "**Expected Output**\n",
    "\n",
    "\n",
    "Unique Product Categories:\n",
    "\n",
    "- Electronics\n",
    "- Apparel\n",
    "- Home Appliances\n",
    "- Literature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15186a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "products = [\n",
    "    {\"product_name\": \"Laptop\", \"category\": \"Electronics\", \"price\": 1200},\n",
    "    {\"product_name\": \"Jeans\", \"category\": \"Apparel\", \"price\": 40},\n",
    "    {\"product_name\": \"Coffee Maker\", \"category\": \"Home Appliances\", \"price\": 80},\n",
    "    {\"product_name\": \"Smartphone\", \"category\": \"Electronics\", \"price\": 999},\n",
    "    {\"product_name\": \"Jacket\", \"category\": \"Apparel\", \"price\": 60},\n",
    "    {\"product_name\": \"Blender\", \"category\": \"Home Appliances\", \"price\": 150},\n",
    "    {\"product_name\": \"Book\", \"category\": \"Literature\", \"price\": 15}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41ecd46a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Product Categories:\n",
      "- Home Appliances\n",
      "- Apparel\n",
      "- Literature\n",
      "- Electronics\n"
     ]
    }
   ],
   "source": [
    "# Using a set to find unique categories\n",
    "unique_categories = {product[\"category\"] for product in products}\n",
    "\n",
    "# Print the unique categories\n",
    "print(\"Unique Product Categories:\")\n",
    "for category in unique_categories:\n",
    "    print(f\"- {category}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d48729e",
   "metadata": {},
   "source": [
    "### Task 2: Audience Analysis for Music Festival Organizer\n",
    "\n",
    "As the other team got occupied with an urgent task, you have been asked to assist another client on an ad-hoc basis. The client is a music festival organizer looking to optimize event planning and marketing strategies by understanding audience overlap between concerts. \n",
    "\n",
    "Your task is to help analyze the data and:\n",
    "\n",
    "1. Identify unique attendees for each concert.\n",
    "2. Find common attendees across the concerts.\n",
    "\n",
    "The attendee data is provided in the next cell. Use set operations to complete the analysis and print a summary of the results.\n",
    "\n",
    "**Expected Output:**\n",
    "\n",
    "Unique Attendees for Each Concert:\n",
    "- Concert A Only: {'Charlie'}\n",
    "- Concert B Only: {'Eve'}\n",
    "- Concert C Only: {'George', 'Elle'}\n",
    "\n",
    "Common Attendees Between All Concerts: {'Bob'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85e5fa89",
   "metadata": {},
   "outputs": [],
   "source": [
    "concert_a_attendees = {\"Alice\", \"Bob\", \"Charlie\", \"Diana\"}\n",
    "concert_b_attendees = {\"Bob\", \"Diana\", \"Eve\", \"Frank\"}\n",
    "concert_c_attendees = {\"Alice\", \"George\", \"Elle\", \"Frank\",\"Bob\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e12c45e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Attendees for Each Concert:\n",
      "- Concert A Only: {'Charlie'}\n",
      "- Concert B Only: {'Eve'}\n",
      "- Concert C Only: {'Elle', 'George'}\n",
      "\n",
      "Common Attendees Between All Concerts: {'Bob'}\n"
     ]
    }
   ],
   "source": [
    "# Find unique attendees for each concert\n",
    "unique_a = concert_a_attendees - (concert_b_attendees | concert_c_attendees)\n",
    "unique_b = concert_b_attendees - (concert_a_attendees | concert_c_attendees)\n",
    "unique_c = concert_c_attendees - (concert_a_attendees | concert_b_attendees)\n",
    "\n",
    "# Find common attendees between all concerts using intersection\n",
    "common_all = concert_a_attendees & concert_b_attendees & concert_c_attendees\n",
    "\n",
    "# Print the results\n",
    "print(\"Unique Attendees for Each Concert:\")\n",
    "print(f\"- Concert A Only: {unique_a}\")\n",
    "print(f\"- Concert B Only: {unique_b}\")\n",
    "print(f\"- Concert C Only: {unique_c}\\n\")\n",
    "print(f\"Common Attendees Between All Concerts: {common_all}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4491455a",
   "metadata": {},
   "source": [
    "### Task 3: Temperature Trend Analysis\n",
    "\n",
    "In this task, you've been assigned to help a client who is analyzing daily temperature records for a month to understand temperature trends. The client is particularly interested in identifying the records when the temperature exceeded **70Â°F.**\n",
    "\n",
    "Your responsibility is to analyze this dataset and extract the records where the maximum temperature was above 70Â°F. \n",
    "\n",
    "Display the filtered temperatures.\n",
    "\n",
    "The temperature data is given in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f2d5e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_temperatures = [68, 71, 74, 69, 70, 71, 68, 73, 72, 71, 70, 74, 72, 68]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b5749cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[71, 74, 71, 73, 72, 71, 74, 72]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter temperatures above 70 using list comprehension\n",
    "filtered_temperatures = [temp for temp in daily_temperatures if temp > 70]\n",
    "filtered_temperatures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45b22dd",
   "metadata": {},
   "source": [
    "### Task 4: Identifying Unique Temperatures\n",
    "\n",
    "The client wants to find all unique temperature values recorded over a month. Your task is to use set comprehension to extract and print the unique temperatures from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1f2756f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{71, 72, 73, 74}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find unique temperatures using set comprehension\n",
    "unique_temperatures = {temp for temp in filtered_temperatures}\n",
    "unique_temperatures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561922e1",
   "metadata": {},
   "source": [
    "### Task 5: Temperature Frequency Analysis\n",
    "\n",
    "Identify how often each temperature was recorded over a month. Your task is to use dictionary comprehension to count and print the occurrences of each temperature in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2cd4b86f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{72: 2, 73: 1, 74: 2, 71: 3}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperature_count = {temp: filtered_temperatures.count(temp) for temp in unique_temperatures}\n",
    "temperature_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606659a9",
   "metadata": {},
   "source": [
    "### Task 6: Social Media Engagement Analysis\n",
    "\n",
    "You are tasked with helping a client analyze their social media data to identify trending hashtags and measure user engagement. Specifically, you need to extract posts that have received more than 100 likes. Your task is to filter these posts and store them in a variable called popular_posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6d3a521",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = [\n",
    "    {\"content\": \"Loving the sunny weather today! #sunny #happy\", \"likes\": 120},\n",
    "    {\"content\": \"Nothing beats a beach day. #beachday #sunny\", \"likes\": 350},\n",
    "    {\"content\": \"A rainy day at home. #rainy #lazyday\", \"likes\": 75},\n",
    "    {\"content\": \"Best coffee in town. #coffeelove #morning\", \"likes\": 180},\n",
    "    {\"content\": \"Can't wait for the weekend. #weekend #party\", \"likes\": 90}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee95c713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Popular Posts (Likes > 100):\n",
      "- 'Loving the sunny weather today! #sunny #happy'\n",
      "- 'Nothing beats a beach day. #beachday #sunny'\n",
      "- 'Best coffee in town. #coffeelove #morning'\n"
     ]
    }
   ],
   "source": [
    "popular_posts = [post['content'] for post in posts if post['likes'] > 100]\n",
    "\n",
    "print(\"Popular Posts (Likes > 100):\")\n",
    "for post in popular_posts:\n",
    "    print(f\"- '{post}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5074b9cb",
   "metadata": {},
   "source": [
    "### Task 7: Unique Hashtag Extraction\n",
    "\n",
    "Building on the previous task, now that you've identified the popular posts, the client wants to understand which hashtags are being used across these posts. Your task is to extract all unique hashtags from the popular posts.\n",
    "\n",
    "The list of popular posts is provided from the previous task.\n",
    "\n",
    "Tip ðŸ’¡: Use set comprehension to achieve this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4702f08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'#beachday', '#coffeelove', '#happy', '#morning', '#sunny'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract unique hashtags from popular posts using set comprehension\n",
    "hashtags = set(tag for post in popular_posts for tag in post.split() if tag.startswith('#'))\n",
    "hashtags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc116a73",
   "metadata": {},
   "source": [
    "### Task 8: Hashtag Frequency Analysis\n",
    "\n",
    "In this task, the client wants to understand how frequently each hashtag appears in the popular posts. Your task is to count the occurrences of each hashtag from the popular posts using dictionary comprehension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2cc73a38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'#sunny': 2, '#beachday': 1, '#morning': 1, '#happy': 1, '#coffeelove': 1}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hashtag_frequency = {tag: sum(tag in post for post in popular_posts) for tag in hashtags}\n",
    "hashtag_frequency"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
